{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ibovespa forecasting using neural networks\n",
    "\n",
    "## Machine Learning Engineer Nanodegree - Capstone Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn import L1Loss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from ibov.utils import load_config\n",
    "from ibov.model import train, torch_data, model_fc1h, model_fc2h, model_lstm\n",
    "from ibov.feature import create_lags, consolidate_features, create_delta_sign\n",
    "from ibov.request import get_history, label_train_test\n",
    "from ibov.metrics import calculate_metrics, model_prediction, benchmark_model, graphical_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config dict\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Configs\n",
    "window = config.get(\"feature\").get(\"window\")\n",
    "variables = config.get(\"feature\").get(\"variables\")\n",
    "test_split = config.get(\"feature\").get(\"split\").get(\"test\")\n",
    "valid_split = config.get(\"feature\").get(\"split\").get(\"valid\")\n",
    "\n",
    "# Data Configs\n",
    "data_dir = config.get(\"data\").get(\"dir\")\n",
    "ibov_ticker = config.get(\"ibov\").get(\"ticker\")\n",
    "history_file = config.get(\"data\").get(\"history\")\n",
    "data_size = config.get(\"data\").get(\"size\")\n",
    "\n",
    "# Model configurations\n",
    "dropout = config.get(\"model\").get(\"dropout\")\n",
    "hidden_layer = config.get(\"model\").get(\"hidden_layer\")\n",
    "lr = config.get(\"model\").get(\"lr\")\n",
    "seed = config.get(\"model\").get(\"seed\")\n",
    "epochs = config.get(\"model\").get(\"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-27a34af086d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save data on disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mibovespa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Label datapoint as train or test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBytesWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mgenericpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_arg_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'join'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/genericpath.py\u001b[0m in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mhasbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             raise TypeError(f'{funcname}() argument must be str, bytes, or '\n\u001b[0m\u001b[1;32m    153\u001b[0m                             f'os.PathLike object, not {s.__class__.__name__!r}') from None\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasstr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Invoke yahoo finance api\n",
    "ibovespa = get_history(ticker=ibov_ticker)[:data_size]\n",
    "\n",
    "# Save data on disk\n",
    "ibovespa.to_csv(os.path.join(data_dir, history_file), index=False)\n",
    "\n",
    "# Label datapoint as train or test dataset\n",
    "ibovespa = label_train_test(ibovespa, split=test_split, split_valid=valid_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Normalization\n",
    "scaler = MinMaxScaler()\n",
    "ibovespa[['close']] = scaler.fit_transform(ibovespa[['close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag variables\n",
    "ibov_lags_df = create_lags(ibovespa, window=window, var=\"close\", index=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sign variables\n",
    "ibov_delta_sign_df = create_delta_sign(ibov_lags_df, var=\"lags\", index=\"date\", window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate raw data with features\n",
    "master_table = consolidate_features(ibovespa, \"date\", ibov_lags_df, ibov_delta_sign_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to torch standard\n",
    "train_loader, train_x_tensor, train_y_tensor = \\\n",
    "    torch_data(master_table, target=\"target\", variables=variables, group_var=\"group\", batch=50, group=\"train\")\n",
    "\n",
    "valid_loader, valid_x_tensor, valid_y_tensor = \\\n",
    "    torch_data(master_table, target=\"target\", variables=variables, group_var=\"group\", batch=50, group=\"valid\")\n",
    "\n",
    "test_loader, test_x_tensor, test_y_tensor = \\\n",
    "    torch_data(master_table, target=\"target\", variables=variables, group_var=\"group\", batch=50, group=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = model_lstm(input_layer=window, hidden_layer=hidden_layer, dropout=dropout)\n",
    "criterion = L1Loss()\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "train(model, train_loader, valid_loader, criterion, optimizer, epochs=epochs, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance on Training dataset\n",
    "train_true, train_pred = model_prediction(model, train_x_tensor, train_y_tensor)\n",
    "calculate_metrics(train_true, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance on Validation dataset\n",
    "valid_true, valid_pred = model_prediction(model, valid_x_tensor, valid_y_tensor)\n",
    "calculate_metrics(valid_true, valid_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance on Test dataset\n",
    "test_true, test_pred = model_prediction(model, test_x_tensor, test_y_tensor)\n",
    "calculate_metrics(test_true, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and Evaludate Benchmark Model\n",
    "bmk_true, bmk_pred = benchmark_model(test_y_tensor, valid_y_tensor)\n",
    "calculate_metrics(bmk_true, bmk_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test dataset graphically\n",
    "graphical_evaluation(test_true, test_pred, bmk_true, bmk_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
