{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ibovespa forecasting using neural networks\n",
    "\n",
    "## Machine Learning Engineer Nanodegree - Capstone Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from torch.nn import L1Loss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from ibov.utils import load_config\n",
    "from ibov.model import train, torch_data, model_fc1h, model_fc2h, model_lstm\n",
    "from ibov.feature import create_lags, consolidate_features, create_delta_sign, label_train_test, Normalize\n",
    "from ibov.request import get_history\n",
    "from ibov.metrics import calculate_metrics, model_prediction, benchmark_model, graphical_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config dict\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Configs\n",
    "window = config.get(\"feature\").get(\"window\")\n",
    "variables = config.get(\"feature\").get(\"variables\")\n",
    "test_split = config.get(\"feature\").get(\"split\").get(\"test\")\n",
    "valid_split = config.get(\"feature\").get(\"split\").get(\"valid\")\n",
    "\n",
    "# Data Configs\n",
    "data_dir = config.get(\"data\").get(\"dir\")\n",
    "ibov_ticker = config.get(\"ibov\").get(\"ticker\")\n",
    "filename = config.get(\"data\").get(\"file\")\n",
    "data_size = config.get(\"data\").get(\"size\")\n",
    "ascending = config.get(\"data\").get(\"ascending\") == 'True'\n",
    "\n",
    "# Model configurations\n",
    "dropout = config.get(\"model\").get(\"dropout\")\n",
    "hidden_layer = config.get(\"model\").get(\"hidden_layer\")\n",
    "lr = config.get(\"model\").get(\"lr\")\n",
    "seed = config.get(\"model\").get(\"seed\")\n",
    "epochs = config.get(\"model\").get(\"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Invoke yahoo finance api\n",
    "#ibovespa = get_history(ticker=ibov_ticker, data_size=data_size, ascending=ascending)\n",
    "\n",
    "# Save data on disk\n",
    "#ibovespa.to_csv(os.path.join(data_dir, filename), index=False)\n",
    "\n",
    "# Read from disk\n",
    "ibovespa = pd.read_csv(os.path.join(data_dir, filename))\n",
    "\n",
    "# Label datapoint as train or test dataset\n",
    "ibovespa = label_train_test(ibovespa, split=test_split, split_valid=valid_split, ascending=ascending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalize()\n",
    "scaler.fit(ibovespa[ibovespa[\"group\"]==\"train\"][[\"close\"]])\n",
    "ibovespa[[\"close\"]] = scaler.transform(ibovespa[[\"close\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag variables\n",
    "ibov_lags_df = create_lags(ibovespa, window=window, var=\"close\", index=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sign variables\n",
    "ibov_delta_sign_df = create_delta_sign(ibov_lags_df, var=\"lags\", index=\"date\", window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate raw data with features\n",
    "master_table = consolidate_features(ibovespa, \"date\", ibov_lags_df, ibov_delta_sign_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to torch standard\n",
    "train_loader, train_x_tensor, train_y_tensor = \\\n",
    "    torch_data(master_table, target=\"target\", variables=variables, group_var=\"group\", batch=50, group=\"train\")\n",
    "\n",
    "valid_loader, valid_x_tensor, valid_y_tensor = \\\n",
    "    torch_data(master_table, target=\"target\", variables=variables, group_var=\"group\", batch=50, group=\"valid\")\n",
    "\n",
    "test_loader, test_x_tensor, test_y_tensor = \\\n",
    "    torch_data(master_table, target=\"target\", variables=variables, group_var=\"group\", batch=50, group=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107379.],\n",
       "       [109786.],\n",
       "       [110133.],\n",
       "       [110227.],\n",
       "       [110575.],\n",
       "       [108888.],\n",
       "       [111335.],\n",
       "       [111814.],\n",
       "       [112919.],\n",
       "       [113682.],\n",
       "       [113625.],\n",
       "       [113571.],\n",
       "       [112722.],\n",
       "       [114992.],\n",
       "       [115323.],\n",
       "       [114975.],\n",
       "       [116146.],\n",
       "       [117947.],\n",
       "       [118157.],\n",
       "       [117679.],\n",
       "       [116016.],\n",
       "       [116348.],\n",
       "       [117857.],\n",
       "       [119051.],\n",
       "       [119475.],\n",
       "       [119306.],\n",
       "       [118558.],\n",
       "       [119223.],\n",
       "       [119851.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.denormalize(test_y_tensor.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_fc1h(nn.Module):\n",
    "\n",
    "    def __init__(self, input_layer, hidden_layer=50, dropout=0.25):\n",
    "\n",
    "        super(model_fc1h, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(input_layer, hidden_layer)\n",
    "        self.fc2 = nn.Linear(hidden_layer, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "\n",
    "        x = self.fc1(input)\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc2(x)\n",
    "\n",
    "        return output[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = model_fc1h(input_layer=window, hidden_layer=hidden_layer, dropout=dropout)\n",
    "criterion = L1Loss()\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:36:32, epoch: 0, train: 2.317, valid: 0.228\n",
      "13:36:32, epoch: 1, train: 1.368, valid: 0.047\n",
      "13:36:32, epoch: 2, train: 0.985, valid: 0.094\n",
      "13:36:32, epoch: 3, train: 0.948, valid: 0.096\n",
      "13:36:32, epoch: 4, train: 0.913, valid: 0.055\n",
      "13:36:32, epoch: 5, train: 0.821, valid: 0.038\n",
      "13:36:32, epoch: 6, train: 0.802, valid: 0.038\n",
      "13:36:32, epoch: 7, train: 0.786, valid: 0.036\n",
      "13:36:32, epoch: 8, train: 0.799, valid: 0.038\n",
      "13:36:32, epoch: 9, train: 0.755, valid: 0.037\n",
      "13:36:32, epoch: 10, train: 0.828, valid: 0.039\n",
      "13:36:32, epoch: 11, train: 0.731, valid: 0.04\n",
      "13:36:32, epoch: 12, train: 0.701, valid: 0.035\n",
      "13:36:32, epoch: 13, train: 0.696, valid: 0.035\n",
      "13:36:32, epoch: 14, train: 0.736, valid: 0.041\n",
      "13:36:32, epoch: 15, train: 0.686, valid: 0.04\n",
      "13:36:32, epoch: 16, train: 0.702, valid: 0.036\n",
      "13:36:32, epoch: 17, train: 0.692, valid: 0.045\n",
      "13:36:32, epoch: 18, train: 0.665, valid: 0.049\n",
      "13:36:32, epoch: 19, train: 0.678, valid: 0.037\n",
      "13:36:32, epoch: 20, train: 0.651, valid: 0.033\n",
      "13:36:32, epoch: 21, train: 0.592, valid: 0.033\n",
      "13:36:32, epoch: 22, train: 0.63, valid: 0.034\n",
      "13:36:32, epoch: 23, train: 0.642, valid: 0.038\n",
      "13:36:32, epoch: 24, train: 0.622, valid: 0.039\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "train(model, train_loader, valid_loader, criterion, optimizer, epochs=epochs, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.maximo = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.maximo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance on Training dataset\n",
    "train_true, train_pred = model_prediction(model, train_x_tensor, train_y_tensor)\n",
    "calculate_metrics(train_true, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance on Validation dataset\n",
    "valid_true, valid_pred = model_prediction(model, valid_x_tensor, valid_y_tensor)\n",
    "calculate_metrics(valid_true, valid_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance on Test dataset\n",
    "test_true, test_pred = model_prediction(model, test_x_tensor, test_y_tensor)\n",
    "calculate_metrics(test_true, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and Evaludate Benchmark Model\n",
    "bmk_true, bmk_pred = benchmark_model(test_y_tensor, valid_y_tensor)\n",
    "calculate_metrics(bmk_true, bmk_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test dataset graphically\n",
    "graphical_evaluation(test_true, test_pred, bmk_true, bmk_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
